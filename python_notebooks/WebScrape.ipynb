{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests\n",
    "# !pip install beautifulsoup4\n",
    "# !pip install gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from gtts import gTTS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skin Cancer \n",
    "#### Website: https://www.skincancer.org/skin-cancer-information/skin-cancer-pictures/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.skincancer.org/skin-cancer-information/skin-cancer-pictures/'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "response = requests.get(url, headers=headers)\n",
    "#print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_types = [\"Basal Cell Carcinoma (BCC)\",\"Squamous Cell Carcinoma (SCC)\",\"Melanoma\", \"Merkel Cell Carcinoma (MCC)\",\n",
    "              \"Actinic Keratosis\"]\n",
    "\n",
    "cancer_ids = ['bcc', 'scc', 'melanoma','merkel','ak']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_cap_cancer(cancer_id):\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    bcc_sec = soup.find('section',attrs = {'id':cancer_id})\n",
    "\n",
    "    sec_img = bcc_sec.find_all('img')\n",
    "    sec_imgs = []\n",
    "    for img in sec_img:\n",
    "        if img.get('src').find(\"https\")== 0:\n",
    "            sec_imgs.append(img.get('src'))\n",
    "\n",
    "    bcc_sec_cap = bcc_sec.find_all('figcaption')\n",
    "    captions = []\n",
    "    for cap in bcc_sec_cap:\n",
    "        captions.append(cap.get_text())\n",
    "\n",
    "    return sec_imgs, captions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'en'    \n",
    "def get_text_to_speech(mytext):\n",
    "    myobj = gTTS(text=mytext, lang=language, slow=False)\n",
    "    return myobj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "id = 0\n",
    "for cancer_type,cancer_id in zip(cancer_types,cancer_ids):\n",
    "    bcc_sec_imgs,captions = get_img_cap_cancer(cancer_id)\n",
    "    for img,cap in zip(bcc_sec_imgs,captions):\n",
    "        get_text_to_speech(cap).save(f\"id_{id}.mp3\")\n",
    "        dataset_cancer_cell = {\n",
    "            'id':id,\n",
    "            'cancer_type':cancer_type,\n",
    "            'cancer_img':img,\n",
    "            'cancer_img_caption':cap,\n",
    "            'caption_speech':f\"id_{id}.mp3\",\n",
    "        }\n",
    "        id += 1\n",
    "        data.append(dataset_cancer_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('skin_cancer_dataset.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating MMBT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5e3be5deec28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# module assumes that the directory where the saved chexnet weight is in the same level as this module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mMMBT_DIR_PARENT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMMBT_DIR_PARENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mMODELS_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# mapping number of image embeddings to AdaptiveAvgPool2d output size\n",
    "POOLING_BREAKDOWN = {1: (1, 1), 2: (2, 1), 3: (3, 1), 4: (2, 2), 5: (5, 1), 6: (3, 2), 7: (7, 1), 8: (4, 2), 9: (3, 3)}\n",
    "\n",
    "# module assumes that the directory where the saved chexnet weight is in the same level as this module\n",
    "MMBT_DIR_PARENT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "DATA_DIR = os.path.join(MMBT_DIR_PARENT, \"data\")\n",
    "MODELS_DIR = os.path.join(DATA_DIR, \"models\")\n",
    "SAVED_CHEXNET = os.path.join(MODELS_DIR, \"saved_chexnet.pt\")\n",
    "\n",
    "\n",
    "class ImageEncoderDenseNet(nn.Module):\n",
    "    def __init__(self, num_image_embeds, saved_model=True, path=os.path.join(MODELS_DIR, SAVED_CHEXNET)):\n",
    "        \"\"\"\n",
    "\n",
    "        :type num_image_embeds: int\n",
    "        :param num_image_embeds: number of image embeddings to generate; 1-9 as they map to specific numbers of pooling\n",
    "        output shape in the 'POOLING_BREAKDOWN'\n",
    "        :param saved_model: True to load saved pre-trained model False to use torch pre-trained model\n",
    "        :param path: path to the saved .pt model file\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if saved_model:\n",
    "            # loading pre-trained weight, e.g. ChexNet\n",
    "            # the model here expects the weight to be regular Tensors and NOT cuda Tensor\n",
    "            model = torch.load(path)\n",
    "            logger.info(f\"Saved model loaded from: {path}\")\n",
    "        else:\n",
    "            model = torchvision.models.densenet121(pretrained=True)\n",
    "\n",
    "        # DenseNet architecture last layer is the classifier; we only want everything before that\n",
    "        modules = list(model.children())[:-1]\n",
    "        self.model = nn.Sequential(*modules)\n",
    "        # self.model same as original DenseNet self.features part of the forward function\n",
    "        self.pool = nn.AdaptiveAvgPool2d(POOLING_BREAKDOWN[num_image_embeds])\n",
    "\n",
    "    def forward(self, input_modal):\n",
    "        \"\"\"\n",
    "        B = batch\n",
    "        N = number of image embeddings\n",
    "        1024 DenseNet embedding size, this can be changed when instantiating MMBTconfig for modal_hidden_size\n",
    "\n",
    "        Bx3x224x224 (this is input shape) -> Bx1024x7x7 (this is shape after DenseNet CNN layers before the last layer)\n",
    "        -> Bx1024xN (this is after torch.flatten step in this function below) -> BxNx1024 (this is the shape of the\n",
    "        output tensor)\n",
    "\n",
    "        :param input_modal: image tensor\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # Bx3x224x224 -> Bx1024x7x7 -> Bx1024xN -> BxNx1024\n",
    "        features = self.model(input_modal)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out = self.pool(out)\n",
    "        out = torch.flatten(out, start_dim=2)\n",
    "        out = out.transpose(1, 2).contiguous()\n",
    "\n",
    "        return out  # BxNx1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
